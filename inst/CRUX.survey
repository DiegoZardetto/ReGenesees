###################################################################
# A partial list of survey package critical bugs that I have been #
# fixing over time.                                               #
# NOTE: This list is not necessarily up-to-date, and bugs are     #
#       listed in no particular order.                            #
###################################################################

1   [svydesign, as.fpc, ...]
    The following documented feature of svydesign: "If fpc is
    specified but for fewer stages than ids sampling is assumed to be
    complete for subsequent stages." was not actually implemented.
    It has been worked out in e.svydesign.

2   [calibrate, svyrecvar, svystat, svyby, ...]
    If aggregate.stage is not NULL regression coefficients are
    computed using averaged direct weights and model matrix elements.
    This regression coefficients then enter residuals computation in
    svyrecvar. As a consequence, one ends up with WRONG SE ESTIMATES
    (in fact model matrix averaging is only an analytic trick to achieve
    identical calibrated weights in clusters, something not meaningful
    from a design based perspective).

2.1 [calibrate, svyrecvar, svystat, svyby, ...]
    The right way to implement calibration on a model defined at
    cluster level is to sum model matrix elements inside clusters
    while "averaging" direct weights, provided they where constant
    inside clusters (otherwise the model has to be kept at unit-level).

3   [unwrap, svyby, coef, SE, cv, ...]
    3.1 Unwrap (local to svyby) was not correctly working for
        FUN=svyratio.
    3.2 Svyby was not correctly working whenever design was
        calibrated AND formula wasn't a formula: problem arose
        because, in this case, formula MUST NOT be subsetted for
        domains.

4   [ftable.svyby, svyby, ...] 
    Whenever the svyby object has been built with the option
    'drop.empty.groups = TRUE' AND there are effectively empty
    groups in data, the ftable.svyby output is WRONGLY FORMATTED
    (due to the wrong way in which statistics and variances fill the
    array rval).

5   [svyby, deff, ...]
    If design is a calibrated object, deff estimates in subppulations
    (as obtained by svyby) are wrong (unless deff="replace"). This is
    because, when subsetting a calibrated object, ONLY weights are
    affected while data are unchanged. As a consequence the number of
    observation per domain is wrong. Another possible error can arise,
    even for deff estimates at the population level (i.e. no svyby),
    if weights have been calibrated in such a way that the estimated
    population size is LESS then the number of sample observations
    (though weird, the latter can happen in practice for calibration
    models not involving explicitly or implicitly an intercept term).

6   [svyby, deff, ...]
    When computing the DEFF of a statistic (total or mean for the
    survey package), svymean gets called from svyvar (generic) and
    here there is no point in estimating the variance of the mean
    (i.e. svyrecvar should not be called). Lumley's solution is
    highly memory and CPU time hungry, without reason. A modified
    z.svyvar which calls a modified function z.svymean (generic,
    since survey.design2 and cal.analytic objects differ only in
    variance estimation) is a good alternative: huge savings of
    memory and cpu time are obtained.
    For instance, try the following with the survey package (you will
    not succeed!):
    library(survey)
    library(ReGenesees)
    data(sbs)
    sbsdes <- svydesign(data= sbs, ids= ~ id, strata= ~ strata,
                        weights= ~ weight, fpc= ~ fpc)
    stat <- svytotal(~area, sbsdes, deff= TRUE)

	to be compared with ReGenesees solution:

    data(sbs)
    des <- e.svydesign(data= sbs, ids= ~ id, strata= ~ strata,
                       weights= ~ weight, fpc= ~ fpc,
                       self.rep.str= NULL, check.data= TRUE)
    stat <- svystatTM(design= des, y= ~ area, by= NULL,
                      estimator= "Total", vartype="se",
                      deff= TRUE, na.rm= FALSE)

7   [svyratio, svyby, ...]
    When computing the linearized variable associated to a nonlinear
    estimater (e.g. a Ratio), svytotal gets called for assessing the
    values around which to expand in Taylor series: here there is no
    point in estimating the variance of the total (i.e. svyrecvar
    should not be called). Lumley's solution is memory and CPU time
    hungry, without reason. A modified z.svytotal (with a survey.design2
    method, since survey.design2 and cal.analytic objects differ only
    in variance estimation) is a good alternative: good savings of
    memory and cpu time are obtained.
    This solution is also exploited in my svystatL, svylin, linearize,
    ... functions.

8  [cal.linear, cal.raking, cal.logit...]
   Bugs fixed as in the EVER package.

9  [calibrate, svyrecvar, svystat, svyby, ...]
   When any calibrated weight happen to be zero, variance estimation
   breaks down due to NaN input to qr.resid inside svyrecvar. This can be
   avoided by using a small cutoff value (say 1E-12) for calibrated weights
   with very small absolute value: obtained results will NOT depend on the
   chosen cutoff value. Negative calibrated weights are OK for variance
   estimation. They would produce problems only when calibrating
   in a chain, since at the second calibration step one has initial weights
   (the calibrated weights at step 1) such that whalf is ill defined.

10 [svyrecvar, svyratio, svyby, ...]
   When the linearized variable corresponding to a non linear estimator is ill
   defined (because the estimator gradient is singular at the Taylor series
   expansion point - a typical case is when, perhaps only inside a single
   estimation domain, the estimate of the denominator total in a ratio is zero)
   svyrecvar leads to an unhandled error for calibrated designs. This error
   arises from the fact that Fortran routine qr.resid cannot cope with NaN, Inf
   and NA values. This behaviour has been fixed: NaN is returned for SE, with a
   warning, but no errors (i.e. computation ends normally).

11 [calibrate, regcalibrate]
   Heteroskedastic assisting models for unbounded linear calibration did not
   actually work due to a bug in regcalibrate (sigma2 <- drop(mm %*% lambda)
   had not the right dimension, fixed).

12 [svyratio, svyby, deff, ...]
   Design Effects for Ratios between Totals (formerly unavailable) are
   correctly computed but badly accessed by extractor function 'deff', due
   to diag(). This causes some estimated Deffs to be lost, both for estimates
   at population and at domain level. Fixed and extended to 'parallel'
   Ratios (i.e. cross=FALSE).

13 [svyby, svytotal, svymean, svyratio, ...]
   na.rm=TRUE causes observations to be dropped (for non calibrated object) or
   weights to be put to zero (for calibrated ones) whenever any of the variables
   in formula happen to have an NA value. This is obviously wrong when e.g.
   formula=~y+x and only x has NAs: estimates on y should not be affected, but
   they surely will be. ReGenesees, on the contrary, allows to specify
   na.rm=TRUE only for estimates computed on just a single variable.
   Moreover, na.rm=FALSE for calibrated objects triggers an unhandled error
   (due to external function call qr.resid) both at population level and for
   domains. 

14 [svyby, svytotal, svymean, svyratio, ...]
   If lonely.psu='average' variance contributions from lonely strata are mapped
   to NA: this is subsequently used by onestage to identify lonely strata and
   to attach to them the average variance computed on non-lonely strata. This
   generates WRONG VARIANCE results when interest variables do have missing
   data because they too generate NA stratum variances. This, in turn,
   eventually affects even variance estimates for variables not containing NAs
   if they are estimated together with variables with missing values. Fixed.

15 [svyby, svytotal, svymean, svyratio, ...]
   na.rm=TRUE causes estimates in subdomains to be based only on non-missing
   values, discarding NAs. If an interest variable has only missing values for
   all the observations falling in a given subdomain, na.rm=TRUE generates a
   unhandled runtime error. Fixed.
